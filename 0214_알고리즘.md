





# DFS 

경로를 찾으면 즉시 이동(stack에 push), 경로를 찾지 못하면, 현재 경로에서 이전 경로로 돌아가서(stack에서 pop) 다시 경로를 찾음.

재귀를 호출하는 것은 스택에 집어넣는 것과 똑같음.

stack으로 DFS 구현시에는 break 이용해서, 새로운 경로 발견 즉시 이동

하지만 재귀에서는, 재귀함수 실행이 해당 위치로 이동을 의미하므로, break 없이 경로 찾으면 함수호출 해주면 됨 / for문에서 경로가 없으면 재귀함수가 호출되지 않아서 재귀함수 호출안되고, 그럼 해당노드가 pop 되는 것



```python
# 공통부분
#--------------------- 공통으로 필요-----------------------------------------------
N = 10
adj = [[0]*N for _ in range(N)]
visited = [False]*N
path = []

for i in range(N-1):
    adj[i][i+1] = 1
    adj[i+1][i] = 1
adj[N-3][N-1] = adj[N-1][N-3] = 1 # N-3 번과 N-1번도 연결

#--------------------------------------------------------------------------------
# 1. stack 이용
stack = []
top = -1
top += 1 # 더 큰수로 이동
start = 0
stack.append(start)
path.append(start)
visited[start] = True
while stack:
    cur = stack[-1]
    
    for i in range(N-1,-1,-1): # 핵시구조 1
        if adj[cur][i] == 1 and visited[i] == False:
            visited[i] = True
            stack.append(i)
            path.append(i)
            break     # 핵심구조 2
    else:
        stack.pop()   # 핵심구조 3


# 2. 재귀이용
	# 함수호출이 stack에 append 하는 것이고, 함수 끝나는 것이 stack에서 pop임.
	
    # v 번 노드에서 경로 찾기
    
    # 방문하지 않은 이동할 곳이 있으면 바로 이동
    
    # 이동할 곳이 없다면 이전 위치로 되돌아가기

def dfs(v): # 이 함수 시작하면, v 번 노드로 이동한다는 의미
    visited[v] = True # v번 노드 방문 표시
    path.append(v)
    for i in range(N-1,-1,-1):
        if adj[v][i] == 1 and not visited[i]:
            dfs(i)
dfs(0) # 0번 노드에서 길찾기 시작
print(path)


```



## 코드구조

1. `for-else` 문으로 `stack.append() - stack.pop()` 진행

2. `for` 에 `break` 와 `for-else` 안쓰고 하려면,  맨 위에 현재 노드 찾을 때, `stack.pop()` 하면 됨 

   ```python
   위의 예에서
   while stack:
       cur = stack.pop()
       path.append(cur)  # 추가된 부분
       # 갈 수 있는 곳 모두 stack에 넣기
       for i in range(N-1,-1,-1):
           if adj[cur][i] == 1 and visited[i] == False:
               visited[i] = True
               stack.append(i)
               #path.append(i)
               #break
       #else:
           #stack.pop()
   
   ```

   

# 후위표기와 계산기











# 백트래킹

## 활용

+ 최적화 문제

+ 결정문제

+ 예
  + 미로찾기, n-Qeen, map coloring, 부분집합, 순열
  
+ 순열

  + 각 요소가 사용되었는지 안되었는지를 알려줄 `used = [0]*N` 필요

    




## 절차

1. 상태 공간 트리의 깊이 우선 검색 실시
1.  각 노드가 유망한지 점검
1. 만일 2의 노드가 유망하지 않으면, 해당 노드의 부모 노드로 돌아가서 검색 계속

+ 해답의 가능성이 있는 경우를 **유망**하다고 함





## DFS 와 백트래킹 차이

+ DFS 는 모든 경우 다 해보고, 끝까지가서 되는지 안되는지 파악
  + 모든 경우의 수 고려

+ 백트래킹은 끝까지 가기 전 경로에서도 되는지 안되는지 파악 (가지치기)
  + 불필요한 경로 조기 차단
+ DFS 와 백트래킹은 코드 구조 같음
  + 백트래킹은 안되는 경우 미리 차단하는 조건 추가된 것









# 부분집합 / 순열

## 1. 부분집합

### [1] 비트 표현



### [2] 부분집합 표현



### [3] 부분집합 합



### [4] 부분집합 합  + 조건 1



### [5] 부분집합 합 + 조건 1, 2





## 2. 순열







# 트리

## 1. 기본트리

### [1] 성질

+ 간선의 수 = 정점의 수 - 1





## 2. 이진트리

### [1] 종류

#### (1) 포화이진트리 / 완전이진트리

+ 부모 node의 숫자 < 자식 node의 숫자
+ 1 번이 root

#### (2) 그외

+ 포화이진트리의 2가지 성립 x

### [2] 성질

+ 부모 index = 자식 index //2
+ 좌측 자식 index = 부모 index * 2 
+ 우측 자식 index = 부모 index*2 +1



### [3] 순회방법

#### (1)

#### (3) 후위순회

```python
# 이진트리의 경우

# 1.특정 노드 아래의 노드 개수 세기
## [1] global 변수 없이하는 법  
### 부모 노드를 index로 하고, child node는 2개의 리스트에 저장되어있음
def order(v):
    if v == 0:  # 노드가 아니면 0 반환
        return 0
    return order(ch1[n]) + order(ch2[n]) + 1  # 자식이 없으면 1 반환
```





### [4] 표현(저장)

+ 배열 저장의 단점

  + 편향 이진 트리의 경우, 사용하지 않는 배열의 원소에 대한 메모리 낭비

  + 트리의 중간에 새로운 노드를 삽입하거나, 기존의 노드를 삭제할 경우, 배열의 크기 변경 어려워 비효율적

    

#### (1) 배열 (성질 이용)

+ 정점의 최대 번호를 모두 포함할 수 있는 index를 가지는 1차원 배열을 생성

+ 완전이진트리에서 이용

  ```python
  # Index는 이진트리에서 위치 번호(1부터 시작)
  tree = [0,'A','B',0,'D',0,0,0,0,0,0,0,0,0,0,0] # 좌편향트리
  ```



+ 장점

  + 완전이진트리의 경우, 부모와 자식간의 관계를 알고 있으므로, tree에 각 노드가 담고있는 value들을 그냥 쉽게 넣을 수 있다. (아래 참고)

  ```python
  # 완전 이진 트리의 in_order
  def in_order(v):
      if v <= N: # 최대 노드 개수 N으로 주어짐
          in_order(v*2) #좌측자식
          print(tree[v],end='')
          in_order(v*2 + 1) # 우측자식
  ```

  

+ 구현

  ```python
  # 0. 트리 저장방법
  tree = [0]*(노드개수+1) # root 가 1부터 시작
  # 그 후 tree[node_idx] = node_value 로 저장해준다.
  ```

  



#### (2) 부모 노드 숫자를 index로 하는 배열 2개에 저장

+ 포화이진트리가 아닌 경우, 저장 공간을 아낄 수 있음

+ 부모 자식간에 임의 규칙으로 연결되었는 경우 이용

  | node index          | 0    | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    |
  | ------------------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
  | child1 ( arr[0] )   | 0    | 2    | 4    | 6    | 8    | 0    | 0    | 0    | 0    |
  | child2 ( arr[1] )   | 0    | 3    | 5    | 7    | 0    | 0    | 0    | 0    | 0    |
  | node value (필요시) | 0    | 값1  | 값2  | 값3  | 값4  | 값5  | 값6  | 값7  | 값8  |
  
  이는 1 번이 root이고, 2,3을 자식으로가지고....반복하는 트리임
  
  ```python
  # 0. 트리 저장방법
  V = int(input()) # 정점 개수와 정점의 키값 일치하는 경우
  arr = [[0]* (V+1) for _ in range(2)]
  E = list(map(int,input().split()))
  
  for i in range(0, len(E),2):
      parent, child = E[i], E[i+1]
      # print(parent, child)
      if arr[0][parent]:
          arr[1][parent] = child
      else:
          arr[0][parent] = child
          
  ```
  
  



#### (3) 자식 노드 숫자를 index로 하는 배열에 , 부모 노드 index 저장

+ 루트 찾기, 조상찾기에 활용 가능
  + 포화 & 완전 이진트리 아닌 경우

| node index | 0    | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    |
| ---------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| parent     | 0    | 0    | 1    | 1    | 2    | 2    | 3    | 3    | 4    |

```python
# 0. 트리 저장방법
parent = [0]*(V+1)
for e in range(E):
    read p, c
    parent[c] = p
	

# 1. 루트찾는 코드
root = 0 
for i in range(1,V+1):
    if parent[i] == 0:
        root = i
        break
print(root)

# 2. 조상찾는 코드
# 5의 조상을 찾아봐라
c = 5
anc = []
while parent[c] != 0 :
    anc.append(parent[c])
    c = parent[c]
print(anc)
```







#### (4) 2차원 배열 비대칭

+ 2차원 배열에서 각 행을 모든 노드로 볼 때, 열에 좌, 우 자식 노드를 1, 2 와 같이 표기
  + 이렇게 하면, 자식 노드가 k 개 있어도 표현 가능







## 3. 그 외 이진트리

### [1] 수식트리





### [2] 이진탐색트리

#### (1) 정의

+ 모든 노드는 유일한 값 가짐
+ 부모 노드의 왼쪽에 있는 노드들의 값은 부모보다 작음
+ 부모 노드의 오른쪽에 있는 노드들의 값은 부모보다 큼



#### (2) 탐색

+ 부등호로 비교해가며 자식들 중 한 쪽 자식의 트리만 탐색하면 됨 







### [3] 힙

+ 정의

  + 완전 이진트리이고,

  + 부모와 자식 간의 대소 관계가 항상 한쪽이 더 크거나, 더 작음

    

+ 활용

  + 우선순위 큐 구현

  + 값 저장하고, 최소값, 최대값 가져오기 위한 자료구조

    + root 의 값을 계속 가져온다고 생각하면 됨(root delete 이용해 힙정렬)

      

+ 구현

  + 마지막 요소 위치 알려주는 변수 필요

  

  

#### (1) 최대힙

+ 정의

  + 키값이 가장 큰 노드를 찾는 완전이진트리


  + 부모 키값 > 자식 키값


  + 루트 : 가장 큰 키값 노드

    


#### (2) 최소힙

+ 정의

  + 키값이 가장 작은 노드를 찾는 완전이진트리


  + 부모 키값 < 자식 키값


  + 루트 : 가장 작은 키값 노드




#### (3) 삽입연산

+ 가장 마지막 노드자리에 삽입 후, 부모와 자식 간에 대소비교하여, 위치 잘 찾아주기



#### (4) 삭제연산

+ 항상 root의 요소를 반환하고, root 없애고, heap 다시 정렬하면 됨
+ 새로 root가 되는 요소
  + 제일 마지막 요소 (나머지는 heap인 상태로 유지됨 + 완전이진트리 유지)
+ 교환 순서
  + 최대힙 : root의 좌, 우 노드 중, 큰 것과 비교
  + 최소힙 : root의 좌, 우 노드 중, 작은 것과 비교









공통조상찾기











# 완전 검색 & 그리디



## 1. 반복과 재귀



## 2. 완전검색기법

+ 모든 경우의 수를 생성하고 테스트하기 때문에 수행 속도는 느리지만, 해답을 찾아내지 못할 확률이 적음

+ 이를 기반으로 그리디 기법이나 동적 계획법을 이용해 효율적인 알고리즘을 찾을 수 있음

+ 우선 완전 검색으로 접근하여, 해답 도출 후, 성능 개선을 위해 다른 알고리즘을 사용해서 해답찾기

+ 완전 검색은 전형적으로 순열, 조합, 부분집합과 같은 조합적 문제들과 연관

  + 완전 검색은 조합적 문제에 대한 brute-force 방법

  





## 3. 조합적 문제

+ 여행사 Big sale 문제



### [1] 순열

+ 다수의 알고리즘 문제들은 순서화된 요소들의 집합에서 최선의 방법을 찾는 것과 관련
  + 예 : Traveling Salesman Problem

#### (1) 순열 생성방법1 (loop)

```python
# 1. {1,2,3}을 이용한 모든 순열
for i1 in range(3):
    for l2 in range(3):
        if l2 != l1:
            for l3 in range(3):
                if l3 != l2 and l3 != l1:
                    print(l1,l2,l3)
```





#### (2) 순열 생성방법2 (최소한의 교환) : 이해가 잘 안가네

```python
# 2. n개원소의 nPn
def perm(i, n):
    if i == n:
        print(p)
        return
    else:
        for j in range(i,N):
            arr[i], arr[j] = arr[j], arr[i]
            print(f"위 i, j : {i} {j}, arr : {arr}")
            perm(i+1,n)
            print(f"아래 i, j : {i} {j}, arr : {arr}")
            print("------------------------------")
        
arr=[1,2,3,4,5]
n = len(arr)
perm(0,n)
```





#### (3) *순열 생성방법3 (used, 재귀 이용)*

+ a의 index에 대해 사전적 순서로 생성됨 (0,1,2 / 0,1,3 / 0,1,4/ 2,3,4 /...)

```python
# 3. used & 재귀 이용해 nPn 구하기
# a = [1,2,3] 경우 3자리 순열
def f(idx, n): # 순열 p[0]*n을 채우는 함수,idx:현재까지 고른개수, n은 주어진 숫자 개수
    if idx == n:
        print("순열완성, 원하는 작업 하세요",p)
        return
    else:
        for i in range(n): # used에서 사용하지 않은 숫자 검색---------이부분이 핵심(loop가 아래에서 재귀적으로 들어가서, 사전적 순서로 순열 만들게 됨)
            if used[i] == 0 : # 앞에서 사용하지 않은 숫자인 경우
                used[i] = 1   # 사용함으로 표시
                p[idx] = a[i] # p[n] 결정
                f(idx+1, n)
                used[i] = 0 # a[i]를 다른 위치에서 사용할 수 있도록 함
    return

a = [1,2,3]
p = [0]*3
used = [0]*3
f(0,3)



# 4. used & 재귀 이용해 nPk 구하기
# a = [1,2,3,4,5] 경우 3자리 순열
def f(idx, k, n):  # 순열 p[0]*k을 채우는 함수, idx :현재까지 고른 개수, k :고를 개수, n :주어진 숫자개수
    if idx == k:
        print("순열완성, 원하는 작업 하세요",p)
    else:
        for i in range(n): # used에서 사용하지 않은 숫자 검색
            if used[i] == 0 : # 앞에서 사용하지 않은 숫자인 경우
                used[i] = 1   # 사용함으로 표시
                p[idx] = a[i] # p[n] 결정
                f(idx+1, k, n)
                used[i] = 0 # a[i]를 다른 위치에서 사용할 수 있도록 함
    return    
a = [1,2,3,4,5]
k = 3
p = [0]*k
used = [0]*len(a)
f(0,3,5)
```



####  (4) 순열생성방법 4 (사용하지 않은 목록 만들기)

+ 백트래킹 이용해서 해결



### [2] 부분집합

+ 다수의 중요 알고리즘들이 원소들의 그룹에서 최적의 부분집합을 찾는 것
  + 예 : 배낭 짐싸기 (knapsack)

#### (1) 부분집합 생성방법1 (loop)



#### (2) *부분집합 생성방법2 (binary counting)*

+ 부분집합을 생성하기 위한 가장 자연스러운 방법 (원소개수 달라져도 적용가능)

+ binary counting은 사전적 순서로 생성하기 위한 가장 간단한 방법

+ binary counting

  + 원소 수에 해당하는 N개의 비트열을 이용

  + n번째 비트값이 1이면, n번째 원소가 포함되었음을 의미

  + | 10진수 | 이진수 | {A,B,C} |
    | ------ | ------ | ------- |
    | 0      | 000    | {}      |
    | 1      | 001    | {A}     |
    | 2      | 010    | {B}     |
    | 3      | 011    | {A,B}   |
    | 4      | 100    | {C}     |
    | 5      | 101    | {A,C}   |
    | 6      | 110    | {B,C}   |
    | 7      | 111    | {A,B,C} |

    

```python
# 2. 
arr = [3,6,7,1,5,4]
N = len(arr)
for i in range(0,(1<<N)): # 1<<N : 부분집합 개수
    for j in range(0,N):  # 원소의 수만큼 비트를 비교
        if i & (1<<j):    # i의 j 번째 비트가 1이면 j번째 원소 출력
            print(arr[j], end = ' ')
    print()
```





#### (3) 부분집합 생성방법3

```python
# 3. 비트 & 재귀 이용
def f(i,N): # i : 부분집합에 포함될지 결정할 원소의 인덱스, N : 전체 원소 개수
    if i == N:  # 한 개의 부분집합 완성
        print(bit, end= ' ')
        for j in range(N):
            if bit[j]:
                print(a[j],end= ' ')
        print()
        
    else:
        # 갈림길이 2번 나오면 2개 적어야
        bit[i] = 1
        f(i+1,N) # i + 1 로 이동
        bit[i] = 0 # bit[i] = 1 인 경우는 다 봤으니까, bit[i] = 0인 경우 가지로 탐색
        f(i+1,N) #i +1 로 이동
    return

a = [1, 2, 3]
bit = [0, 0, 0]

f(0,3)
```









### [3] 조합

+ 성질

$$
_nC_r = _{n-1}C_{r-1} + _{n-1}C_r
$$



#### (1) 조합 생성방법1 (재귀호출)

+ 위의 성질 이용

```python
# 1. p43 좀 복잡
arr = [1,2,3,4,5]
n = len(arr)
r = 3
p = [0]*r

def comb(n,r):
    if r == 0:
        print(p)
        return
    elif n < r:
        return
        
        
    else:
        p[r-1] = arr[n-1]
        comb(n-1,r-1)
        comb(n-1,r)
```





#### (2) 조합 생성방법2 (r이 작은 경우 / loop)

```python
# 2. 10개의 원소중 3개를 고르는 조합
a = [0,1,2,3,4,5,6,7,8,9]

def f(i,j,k):
    print(i,j,k)

N = 10
R = 3
for i in range(N-2):
    for j in range(i,N-1):
        for k in rnage(j,N):
            f(a[i],a[j],a[k]) # 완성된 조합 {a[i],a[j],a[k]}로 원하는 작업 f 수행


```



#### (3) ***조합 생성방법3 (재귀)***

+ n과 r이 계속 바뀌는 경우로 **조합 생성방법2** 의 재귀적 표현

```python
# 3. 기본형
def nCr(n,r,s): # n개에서 r개를 고르는 조합, s: 선택할 수 있는 구간의 시작
    if r == 0: # 더 이상 고를 것이 없다
        print(*comb)
    else:
        for i in range(s, n-(r-1)):
            comb[r-1] = a[i]
            # comb[3-r] = a[i] 로 하면 사전순으로 나옴
            nCr(n,r-1,i+1)
    return


n = 5
r = 3
# k = r  아래 변형에 이용
a = [i for i in range(1,n+1)]
comb = [0]*r
nCr(n,r,0)


# 3. 변형 (사전순출력)
def nCr(n,r,s,k): # n개에서 r개를 고르는 조합, s: 선택할 수 있는 구간의 시작, k: 전체 선택해야하는 개수
    if r == 0: # 더 이상 고를 것이 없다
        print(*comb)
    else:
        for i in range(s, n-(r-1)):
            comb[k-r] = a[i] # 로 하면 사전순으로 나옴
            nCr(n,r-1,i+1,k)
    return
```



#### (4) 조합 생성방법4 (재귀)

+ **조합 생성방법3** 과 같음

```python
def nCr(n,r,s,k): # n개에서 r개를 고르는 조합, s: 선택구간 시작, k:고른 개수
    if k == r:
        print(*comb)
    else:
        for i in range(s, n-r+k+1)
        comb[k] = a[i]
        nCr(n,r,i+1,k+1)
    return
n = 5
r = 3
a = [i for i in range(1,n+1)]
comb = [0]*r
nCr(n,r,0,0)
        
```



#### (5) 조합 생성방법5

```python
arr = [1,2,3,4,5]
n = 5
r = 3

def comb(selected, idx, cnt):
    if cnt == r:
        print(selected)
        return
    
    if idx >=n:
        return
        
    selected[idx] = 1
    comb(selected, idx+1, cnt+1)
    selected[idx] = 0
    comb(selected, idx+1, cnt)
```



## 4. 탐욕 알고리즘

+ 탐욕 알고리즘은 그 순간에 최적이라고 생각되는 것을 선택해 나가는 방식으로 진행

  + 지역 최적이지만, 전역최적 보장 없음

  + 예 

    + 거스름돈 문제
    + 활동 선택 문제(회의실 1개에서 최대한 많은 회의를 진행하려면, 회의 배치를 어떻게?)
      + 끝나는 시간이 가장 빠른 것부터 선택해서, 해당 회의 끝난 후에 가장 빨리 끝나는 회의를 반복 선택
      + 구체적 방법은 1. 종료시간이 빠른 순서로 활동 정렬/ 2. 첫활동 선택 / 3.선택한 활동의 종료시간보다 빠르게 시작하는 활동 모두 제거 / 4. 남은 활동들에 위 과정 반복

  + 반례 

    +  배낭짐싸기(Knapsack)(백트래킹,dp이용해야)

    

+ 일단 한번 선택된 것은 번복하지 않음

  + 알고리즘이 단순하고, 제한적인 문제들에 적용





+ **원문제의 최적해 = 탐욕적 선택 + 하위 문제의 최적해**





### [1] 동적계획법(DP)와 비교

| 탐욕                                      | DP                                                         |
| ----------------------------------------- | ---------------------------------------------------------- |
| 매 단계에서, 지역 최적 선택 (top-down)    | 매 단계의 해결은, 해결한 하위 문제의 해를 기반 (Bottom-up) |
| 하위 문제를 풀기전에 선택이 먼저 이루어짐 | 하위문제 우선 해결                                         |
| 빠르고 간결                               | 좀 더 느리고 복잡                                          |





### [2] 대표적 탐욕기법 알고리즘

| 알고리즘            | 목적                                                   | 설명                                                         | 대상   |
| ------------------- | ------------------------------------------------------ | ------------------------------------------------------------ | ------ |
| Prim                | N개 노드에 대한 최소 신장 트리(MST) 찾기               | 서브트리 확장하면서 MST 찾기                                 | 그래프 |
| Kruskal             | N개 노드에 대한 최소 신장 트리(MST) 찾기               | 싸이클이 없는 서브 그래프를 확장하면서 MST 찾기              | 그래프 |
| Dijkstra            | 주어진 정점에서, 다른 정점들에 대한 최단경로 찾기      | 주어진 정점에서 가장 가까운 정점을 찾고, 그 다음 정점을 반복해서 찾기 | 그래프 |
| Huffman tree & code | 문서의 압축을 위해, 문자들의 빈도수에 따라 코드값 부여 | 출현 빈도가 낮은 문자부터 선택해, 이진트리 완성하고, 코드값 부여 | 문자열 |

+ Prim 과 Dijkstra가 상당히 비슷









# 분할정복/백트래킹

## 1. 분할정복

+ Top-down approach
+ 분할 -> 정복 -> 통합
  + 분할 : 해결할 문제를 여러 개의 작은 부분으로 나눔
  + 정복 : 나눈 작은 문제를 각각 해결
  + 통합 : 해결된 답을 모음



### [1] 분할 정복 기반 알고리즘

#### (1) 거듭제곱

+ 반복으로 하면 O(n)의 시간이 들지만, 분할 정복으로하면, O(logn)


#### (2) 병합정렬 (merge sort)

+ 여러 개의 정렬된 자료의 집합을 병합하여, 한 개의 정렬된 집합으로 만드는 방식

+ 시간복잡도 : O(logn)

+ 자바의 경우 자료가 큰 경우에 내장으로 활용

  + 자바의 경우 자료가 작으면 quick sort 이용

+ 서로 다른 파일의 것들 가져와서 병합하는 경우에도 활용

  

##### (a) 단계

+ 분할단계
  + 전체 자료 집합에 대하여, 최소 크기의 부분집합이 될 때까지 분할 계속

+ 병합단계
  + 2개의 부분집합을 정렬하면서 하나의 집합으로 병합



##### (b) 복잡도

+ 시간
  + 평균 O(nlogn)

+ 메모리

  + O(n) 사용으로 큼
  + 저장공간은 temp로 이용하고, idx를 전달해서 정렬

  



##### (c) 코드

```python
# 1. 배열이용

def merge_sort1(L):
    if len(L) <= 1:
        return L
    mid = len(L) // 2
    left = merge_sort1(L[:mid])  # 리스트 복사해서 넘기므로 메모리 O(n)만큼 필요
    right = merge_sort1(L[mid:])  # 이렇게 슬라이싱 하면, 여기서도 n 만큼 시간 듦

    return merge(left, right)


def merge(left, right):
    global cnt
    l, r = 0, 0  # k는 삽입되는 index 위치
    result = []  # 결과 내보내는 것도 메모리 필요

    if left[-1] > right[-1]:
        cnt += 1

    while l < len(left)  and r < len(right):
        if left[l] <= right[r]:
            result.append(left[l])
            l += 1
        else:
            result.append(right[r])
            r += 1


    result += left[l:] + right[r:]
    return result

# 2. index + 배열 이용
def merge_sort2(L,start, end):
    if start == end:
        return [L[start]]
    mid = start + (end - start) // 2 # 짝수일 때, 좌측 mid 선택

    left = merge_sort2(L, start, mid)
    right = merge_sort2(L, mid+1 , end)
    return merge(left, right)

#-------------------------------------------------------------------------------------#

# 3. index 이용
def merge_sort3(L, start, end):
    if start == end:
        return
    mid = start + (end-start) // 2  # 2개 남았을 때, 좌측 mid 선택되도록
    mid = (start+end)//2
    # print(L,start,mid,end)
    merge_sort3(L, start, mid)
    merge_sort3(L, mid+1 , end)      # mid 부터 우측
    merge3(L, start,mid,end)

# merge 해야하는 길이와 같은 리스트 만들어서, merge 후, L에 다시 복사
def merge3(L, start, mid, end):
    result = []
    i = start # left의 시작점
    j = mid+1   # right의 시작점

    while i <= mid and j <= end:
        if L[i] <= L[j]:
            result.append(L[i])
            i += 1
        else:
            result.append(L[j])
            j += 1

    if i == (mid+1):
        result += L[j:end+1]

    if j == end+1:
        result += L[i:mid+1]

    # 결과를 L에 복사
    for i in range(start,end+1):
        L[i] = result[i-start]
    # L[start:end+1] = result


L = [10,9,4,1,5,2,8]
merge_sort3(L,0,6)
print(L)
 #------------------------------------------시간측정-----------------------------------
import time
L = [10,9,4,1,5,2,8,1,3,2,1,3,2,1,3,5,5,5,5,66,6,76,3,4532,4,14,21,421,4,214,214,12,321,3235,1,325,43,5,346,34643,234]*100
n = len(L)

s1 = time.time()
for _ in range(100):
    L = [10, 9, 4, 1, 5, 2, 8, 1, 3, 2, 1, 3, 2, 1, 3, 5, 5, 5, 5, 66, 6, 76, 3, 4532, 4, 14, 21, 421, 4, 214, 214, 12,
         321, 3235, 1, 325, 43, 5, 346, 34643, 234] * 100
    merge_sort1(L)
# print(r)
e1 = time.time()


L = [10,9,4,1,5,2,8,1,3,2,1,3,2,1,3,5,5,5,5,66,6,76,3,4532,4,14,21,421,4,214,214,12,321,3235,1,325,43,5,346,34643,234]*1000
s2 = time.time()
for _ in range(100):
    L = [10, 9, 4, 1, 5, 2, 8, 1, 3, 2, 1, 3, 2, 1, 3, 5, 5, 5, 5, 66, 6, 76, 3, 4532, 4, 14, 21, 421, 4, 214, 214, 12,
         321, 3235, 1, 325, 43, 5, 346, 34643, 234] * 100
    merge_sort2(L,0,n-1)

e2 = time.time()


s3 = time.time()
for _ in range(100):
    L = [10, 9, 4, 1, 5, 2, 8, 1, 3, 2, 1, 3, 2, 1, 3, 5, 5, 5, 5, 66, 6, 76, 3, 4532, 4, 14, 21, 421, 4, 214, 214, 12,
         321, 3235, 1, 325, 43, 5, 346, 34643, 234] * 100
    merge_sort3(L,0,n-1)
e3 = time.time()

print(f"{e1-s1:.10f} {e2-s2:.10f}  { e3-s3:.10f}") # 속도가 비슷해..
    
```







#### (3) 퀵 정렬

##### (a)  단계

+ 주어진 배열을 두 개로 분할하고, 각각을 정렬

  

##### (b) 복잡도

+ 시간
  + 평균 O(nlogn)
  + 최악 O(n^2) : 이미 많이 정렬되어있는데, pivot을 양 끝에서 정할 때
+ 공간
  + 평균 O(logn) : 재귀때문
  + 최악 O(n)





##### (c) 코드

```python
# left, right : 정렬하고자 하는 구간
def quick_sort(L:list, left:int, right:int):
    if left < right:
        pivot_loc = partition(L,left, right) # pivot으로 정한 값의 위치
        quick_sort(L, left, pivot_loc-1)
        quick_sort(L, pivot_loc+1, right)
```



##### (d) partition code

+ **pivot 값 기준으로, 작은 값, 큰 값 분리 하는 용도**
+ pivot은 좌 끝 값, 우 끝 값, 배열의 임의의 3개 값의 중간값 등으로 이용



###### (d)-1 : Hoare partition

+ 좌측 끝(i)와 우측 끝(j) 에서 안쪽으로 좁혀가며 pivot의 위치 찾기
+ 아래는 좌측 끝 값을 pivot으로 한 경우 코드

```python
# 1. Hoare partition : 제일 많이 쓰임 / 좌,우 맨 끝에서 시작해서, 안쪽으로 오면서 pivot 위치찾기
def partition(L, left, right): 
    pivot = L[left] # 이 경우, 왼쪽 끝값으로 pivot 설정
    i = left
    j = right
    # |pivot=i|작|작|큰|작|큰|큰|작|큰|큰=j| 로 시작
    while i <= j :
        # 아래 i<=j 등호는 [5,1] 정렬하는 경우 생각해면 이해감
        # 즉 등호는 j가 pivot의 올바른 위치에서 시작하는 경우에 발생
        
        while i<=j and L[i] <= pivot: # 왼편에서 pivot보다 큰 값을 찾는 것
            i += 1
            # 아래는 while문에서 움직이는 것 표현
            # |pivot|작=i|작|큰|작|큰|큰|작|큰|큰=j|
            # |pivot|작|작=i|큰|작|큰|큰|작|큰|큰=j|
            # |pivot|작|작|큰=i|작|큰|큰|작|큰|큰=j|
        while (i <=j 생략가능) and L[j] > pivot:# 오른편에서 pivot보다 작은 값 찾는 것
            j -= 1
        if i < j:
            L[i], L[j] = L[j],L[i]
            # |pivot|작|작|큰=i|작|큰|큰|작=j|큰|큰| 여기서 i,j index원소 교환. 작: pivot보다 작은 것, 큰 : pivot 보다 큰 것
            
    # 마지막에 j가 i보다 작아지면서 끝남
    # 이 경우 |pivot|작|작|작|작 = j|큰 = i|큰|큰|큰| 과 같이 끝나는 것임
    # 그래서 pivot과 j 번재 index 값을 교환
    L[left], L[j] = L[j], L[left]    
    return j

```

###### (d)-2 : Hoare partition

+ 우측 끝 값을 pivot으로 사용한 경우

```python
# 2. Lomuto partition : 코드 간결하지만, 1.보다 느림
def partition(L,left,right)
    pivot = L[right]
    i = left - 1
    for j in range(left,right+1):
    # i|작=j|작|작|큰|큰|작|큰|큰|pivot| 에서 시작
        if L[j] <= pivot:
            i += 1                   # if 문이 계속 만족되면 이 부분에서 i가 j와 같아짐
            L[i], L[j] = L[j], L[i] # -** 에서의 i가 i+=1 되고, i와 j 위치 교환
        # 만약 if 문이 만족안되면, j는 for loop으로 커지고, i는 그대로라 j와 i의 차가 커짐
        # 만약 연속 n 번 if 문 만족안하면, 여기 위치에서 j = i + n 임 -*
        # 즉 *에서의 상태는 i의 바로 오른쪽에는 pivot보다 큰 것이 n개 연속있음 -**
        # 즉 이와 같음 : |작|작|작=i|큰|큰|작=j|큰|큰|pivot| -**
        
        L[i+1], L[j] = L[j], L[i+1]
        return i + 1
    
              
    
    
    
```



+ Lomuto partition

| i    | left, j |       |      |       |         |       |       |       | right     |
| ---- | ------- | ----- | ---- | ----- | ------- | ----- | ----- | ----- | --------- |
| j=   | 3  : i  | 2 : j | 4    | 6     | 9       | 1     | 8     | 7     | 5 = pivot |
|      | 3       | 2     | 4    | 6     | 9       | 1     | 8     | 7     | 5         |
|      | 3       | 2     | 4    | 6     | 9       | 1     | 8     | 7     | 5         |
|      | 3       | 2     | 4    | 6     | 9       | 1     | 8     | 7     | 5         |
|      | 3       | 2     | 4    | **6** | **9**   | 1     | 8     | 7     | 5         |
|      | 3       | 2     | 4    | *1*   | **9**   | *6*   | 8     | 7     | 5         |
|      | 3       | 2     | 4    | 1     | **9**   | **6** | **8** | **7** | 5         |
|      | 3       | 2     | 4    | 1     | ***5*** | 6     | 8     | 7     | 9         |



#### (4) 이진 검색 (binary search)

+ 자료가 정렬된 상태여야 함
+ 100만개 대상에서 1000번 찾는 거 해야하는 경우, 빠르게 가능



##### (a) 과정

+ 중앙 원소 고르기
+ 중앙 원소와 찾고자 하는 값 비교 후, 좌, 우 중 한 곳으로 이동해서, 과정 반복

##### (b) 코드

```python
# 1. 반복문 이용
# L : 배열, n : L의 크기, goal_num : 찾고자 하는 목표값
def bs(L, n, goal_num):
    low = 0
    high = n-1
    
    while low <= high:
        mid = low + (high-low)//2 # 짝수개 존재시, 왼쪽 것이 mid / overflow 방지
        
        if L[mid] == goal_num:
            return mid
        elif L[mid] > goal_num:
            high = mid - 1
        else: # L[mid] < goal_num
            low = mid + 1
    return -1 # goal_num not in L
        

# 2. 재귀 이용
def bs(L, low, high, goal_num):
    if low > high:
        return -1
    
    else:
        mid = low + (high-low)//2
        if L[mid] == goal_num:
            return mid
        elif L[mid] > goal_num:
            return bs(L,mid+1, high, goal_num)
        else: # L[mid] < goal_num:
            return bs(L,low, mid-1, goal_num)
            
```







## 2. 백트래킹

+ 교재에서는 DFS 도중 유망한지 점검해서, 유망하지 않으면 가지치기 함

+ code

  ```python
  ```

  

### [1] 예시

#### (1) N-queen

+ 체스에서 N 개의 퀸을 서로 공격하지 못하게 배열하는 경우의 수 

##### (a) 코드

```python
def nqueen(arr:체스판, cur_node):
    if promising(cur_node):
        if cur_node에서 전체 답이 구해졌다:
            해에 추가
        else:
            for child of cur_node:
                nqueen(child)
                
def nqueen(arr, cur_node):
    if cur_node가 답 완결:
        해에추가
    else:
        for child of cur_node:
            if promising(child):
                nqueen(child)

# 2차원 arr의 index에 대해, 
# 오른쪽 아래 방향(\) 대각선은 (r,c)에서 r-c = -(N-1), -(N-2) , ... 0, 1, ... N-2, N-1         # 왼쪽 아래 방향(/) 대각선은 (r,c)에서 r+c = 0, 1, 2, 3, ... , 2N-2  
N = 8
arr = [[0]*N for _ in range(N)]
col = [0]*N
right_diag = [0]*(2*N-1) # r-c = -(N-1), -(N-2) , ... 0, 1, ... N-2, N-1  
left_diag = [0]*(2*N-1) # r+c = 0, 1, 2, 3, ... , 2N-2
result = 0
def nqueen(cur_r):
    r  = cur_r
    if r == N:
        result += 1
        
    else:
        for c in range(N):
           cr, cc = r, c
           if promising(cr,cc):
                col[cc] = 1
                right_diag[N-1 +(cr-cc)] = 1
                left_diag[cr+cc] = 1
                nqueen(cr + 1)
                col[cc] = 0
                right_diag[N-1 +(cr-cc)] = 0
                left_diag[cr+cc] = 0
                
    return


def promising(cr,cc):
    if col[cc] == 0 and right_diag[N-1+(cr-cc)] == 0 and left_diag[cr+cc] == 0:
        return True
    else:
        return False
       
    
```







## 3. 트리

### [1] 개념

#### (1) 정의

+ 트리는 **사이클이 없는 무향 연결 그래프**

#### (2) 성질

+ 두 노드 사이에는 **유일한 경로**가 존재

+ 비선형 구조로 원소들 간에 1:n 관계를 가지는 자료구조

+ 원소들 간에 계층관계를 가지는 계층형 자료구조

+ 높이가 h인 이진 트리의 경우

+ $$
  \text{ 최소 } h+1, \text{ 최대 } 2^{h+1}-1 \text{ 개 노드 가짐}
  $$

+ 


#### (3) 용어

+ 노드 차수 : 노드에 연결된 자식의 수
+ 높이 :  루트에서 노드에 이르는 간선의 수



### [2] 이진 트리

#### (1) 포화이진트리

+ 모든 레벨에 노드가 포화상태로 채워져 있는 이진 트리
+ 부모 index = 자식 index//2
+ 왼,오 자식 index =  2\*부모index, 2\*부모index+1



#### (2) 완전이진트리

+ index 순서대로 빠짐없이 채워진 이진트리

+ 부모 index = 자식 index//2
+ 왼,오 자식 index =  2\*부모index, 2\*부모index+1



#### (3)편향이진트리



### [3] 이진 트리 순회

+ 순회는 트리의 노드들을 체계적으로 방문하는 것
+ 아래의 코드들은 자식 없어도 방문하는 방식의 코드

#### (1) 전위순회

+ parent, left, right 순으로 순회

+ code

  ```python
  def pre_order(node):
      if node:
          visit(node)
          pre_order(node.left)
          pre_order(node.right)
  
  # 완전 이진 트리의 pre_order
  def pre_order(v):
      if v <= N: # 최대 노드 개수 N으로 주어짐
          print(tree[v],end='')
          pre_order(v*2) #좌측자식        
          pre_order(v*2 + 1) # 우측자식
  ```



#### (2) 중위순회

+ left, parent, right 순으로 순회

+ code

  ```python
  def in_order(node):
      if node:
          in_order(node.left)
          visit(node)
          in_order(node.right)
  ```

  

#### (3) 후위순회

+ left, right, parent 순으로 순회

+ code

  ```python
  def post_order(node):
      if node:
          post_order(node.left)
          post_order(node.right)
          visit(node)
  ```




## [4] 이진트리저장

### (1) 배열이용

#### (a)

#### (b)

#### (c)

#### (d)





### (2) linked list 이용

+ 메모리 공간 낭비 줄일 수 있음



### [5] 이진탐색트리

#### (1) 정의

+ 왼쪽 자식 노드 (key)값 < 부모노드 (key)값 < 오른쪽 자식 노드 (key)값

#### (2) 연산

+ 삽입
+ 삭제





## [5] 힙(heap)

### (1) 정의

+ 완전 이진 트리에 있는 노드 중에서, key 값이 가장 큰 노드나, 가장 작은 노드를 찾기위해 만든 자료구조

+ 최소힙
  + 키 값이 가장 작은 노드(root)를 찾기 위한 **완전이진트리**
  + 부모의 노드 key값이 자식보다 항상 작음
+ 최대힙
  + 키 값이 가장 큰 노드(root)를 찾기 위한 **완전이진트리**
  + 부모의 노드 key값이 자식보다 항상 큼

### (2) 연산

+ 항상 마지막 정점(노드 위치)을 업데이트 하는 것을 시작으로, 부모 자식간 비교를 시작

  + 삽입시에는 맨뒤에 삽입
  + 삭제시에는 맨뒤의 것을 root로 옮기기

+ 노드 1개 삽입/삭제의 시간복잡도

  + O(logn)

+ 최대/최소값 시간복잡도

  + O(1)

  

#### (a) 삽입

+ code

  ```python
  # 1. 최대힙 insert
  def insert(n):
      global last
      last += 1
      tree[last] = n
      child = last
      parent = c//2
      while parent >=1 and tree[parent] < tree[child]: # 부모가 존재하는 동안만 비교가능
          tree[parent] , tree[child] = tree[child], tree[parent]
          child = parent
          parent = parent//2
          
  ```

  

#### (b) 삭제

+ 힙에서는 root만 삭제 후 반환 가능

+ 최대(최소)힙에서 root 삭제

  + 최대(최소)값 나옴

+ code

  ```python
  # 1. 최대힙 delete
  def delete(tree):
      root = tree[1] # root의 key값
      global last
      tree[1] = tree[last]
      last -= 1
      
      parent = 1
      child = parent*2 # 두 자식 + parent 중 제일 큰 것이 parent가 되어야
      while child <= last:
          # 아래 if 문 안 지나면, 오른쪽 자식이 없거나, 왼쪽 자식이 오른쪽 자식보다 큼
          if child + 1 <= last and tree[child] < tree[child+1]: # 오른쪽 자식 노드 있고, 더 크면
              child = child + 1
          if tree[child] > tree[parent]:
              tree[child], tree[parent] = tree[parent], tree[child]
              parent = child
              child = parent*2
      
      return root
      
  
  
  ```







### (3) 활용

#### (a) 우선순위 큐



#### (b) 정렬





# 참고사항

## 1. SWEA

+ 제한시간 1초문제 : C/C++ 기준 10억번 반복 (1억 반복에 10억연산의미)
  + 1억회 반복정도로 해야, 안전하게 다른 연산까지 가능
  + 12! = 4억7900만
